{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81eb6aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Anfel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "# Download the stopwords corpus\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define Arabic stopwords\n",
    "stopwords_list = stopwords.words('arabic')\n",
    "\n",
    "# Read the TSV file\n",
    "data = pd.read_csv(\"merged_reviews_finalDS.tsv\", delimiter='\\t')\n",
    "\n",
    "# Rename the columns if necessary\n",
    "data.columns = ['text', 'label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7def9623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels: [ 1  0 -1]\n"
     ]
    }
   ],
   "source": [
    "unique_labels = data['label'].unique()\n",
    "print(\"Unique labels:\", unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "334765d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...      1\n",
       "1  أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...      1\n",
       "2  هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...      1\n",
       "3  خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...      1\n",
       "4  ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccce381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "# Define functions for text cleaning\n",
    "def clean_text(text):\n",
    "    # Remove non-Arabic characters\n",
    "    arabic_text = re.sub(r'[^\\u0600-\\u06FF\\s]', '', text)\n",
    "    # Remove extra whitespaces\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', arabic_text).strip()\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "     # Split text into words\n",
    "    words = text.split()\n",
    "    # Remove stopwords\n",
    "    text_without_stopwords = [word for word in words if word not in stopwords_list]\n",
    "    # Join words back into a sentence\n",
    "    return ' '.join(text_without_stopwords)\n",
    "\n",
    "# Apply text cleaning functions to the 'text' column\n",
    "data['cleaned_text'] = data['text'].apply(clean_text)\n",
    "data['cleaned_text'] = data['cleaned_text'].apply(remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f12b8093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...</td>\n",
       "      <td>1</td>\n",
       "      <td>ممتاز نوعا النظافة والموقع والتجهيز والشاطيء ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...</td>\n",
       "      <td>1</td>\n",
       "      <td>أسباب نجاح الإمارات شخص الدولة يعشق ترابها نحب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...</td>\n",
       "      <td>1</td>\n",
       "      <td>هادفة وقوية تنقلك صخب شوارع القاهرة الى هدوء ج...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...</td>\n",
       "      <td>1</td>\n",
       "      <td>خلصنا مبدئيا اللي مستني ابهار زي الفيل الازرق ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل...</td>\n",
       "      <td>1</td>\n",
       "      <td>ياسات جلوريا جزء يتجزأ دبي فندق متكامل الخدمات...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...      1   \n",
       "1  أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...      1   \n",
       "2  هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...      1   \n",
       "3  خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...      1   \n",
       "4  ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل...      1   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  ممتاز نوعا النظافة والموقع والتجهيز والشاطيء ا...  \n",
       "1  أسباب نجاح الإمارات شخص الدولة يعشق ترابها نحب...  \n",
       "2  هادفة وقوية تنقلك صخب شوارع القاهرة الى هدوء ج...  \n",
       "3  خلصنا مبدئيا اللي مستني ابهار زي الفيل الازرق ...  \n",
       "4  ياسات جلوريا جزء يتجزأ دبي فندق متكامل الخدمات...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2ace48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 131819\n",
      "Test set size: 32955\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verify the sizes of the train and test sets\n",
    "print(\"Train set size:\", len(train_data))\n",
    "print(\"Test set size:\", len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a787e290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60537</th>\n",
       "      <td>مرضي. سهولة تسجيل الوصول وكمان الخروج على السا...</td>\n",
       "      <td>0</td>\n",
       "      <td>مرضي سهولة تسجيل الوصول وكمان الخروج الساحه وا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51208</th>\n",
       "      <td>بحب الشعر العامى جداااا. بس بحب يكون فية وزن. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>بحب الشعر العامى جداااا بحب يكون فية وزن وده ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17965</th>\n",
       "      <td>جيد. هدوء المكانقربه من المطاعم.</td>\n",
       "      <td>1</td>\n",
       "      <td>جيد هدوء المكانقربه المطاعم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50474</th>\n",
       "      <td>هربت من قبرها جليلة. كيف؟. ومع من ؟. وماهي حقي...</td>\n",
       "      <td>0</td>\n",
       "      <td>هربت قبرها جليلة كيف؟ ومع ؟ وماهي حقيقة الهروب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15842</th>\n",
       "      <td>سلطنة عمان . اعجبني الطاقم كان ودود وحسن الظيا...</td>\n",
       "      <td>1</td>\n",
       "      <td>سلطنة عمان اعجبني الطاقم ودود وحسن الظيافة الم...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  \\\n",
       "60537  مرضي. سهولة تسجيل الوصول وكمان الخروج على السا...      0   \n",
       "51208  بحب الشعر العامى جداااا. بس بحب يكون فية وزن. ...      0   \n",
       "17965                   جيد. هدوء المكانقربه من المطاعم.      1   \n",
       "50474  هربت من قبرها جليلة. كيف؟. ومع من ؟. وماهي حقي...      0   \n",
       "15842  سلطنة عمان . اعجبني الطاقم كان ودود وحسن الظيا...      1   \n",
       "\n",
       "                                            cleaned_text  \n",
       "60537  مرضي سهولة تسجيل الوصول وكمان الخروج الساحه وا...  \n",
       "51208  بحب الشعر العامى جداااا بحب يكون فية وزن وده ا...  \n",
       "17965                        جيد هدوء المكانقربه المطاعم  \n",
       "50474  هربت قبرها جليلة كيف؟ ومع ؟ وماهي حقيقة الهروب...  \n",
       "15842  سلطنة عمان اعجبني الطاقم ودود وحسن الظيافة الم...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c83334c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances for each label:\n",
      "{-1: 41941, 0: 45705, 1: 77128}\n"
     ]
    }
   ],
   "source": [
    "label_counts = np.bincount(data['label'] + 1)  # Shift labels to start from 0\n",
    "label_counts_dict = {-1: label_counts[0], 0: label_counts[1], 1: label_counts[2]}\n",
    "\n",
    "print(\"Number of instances for each label:\")\n",
    "print(label_counts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8dabb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\anfel\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in c:\\users\\anfel\\anaconda3\\lib\\site-packages (0.17.2)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\anfel\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\anfel\\anaconda3\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\anfel\\anaconda3\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\anfel\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\anfel\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\anfel\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\anfel\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\anfel\\anaconda3\\lib\\site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\anfel\\anaconda3\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\anfel\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\anfel\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c7a7e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for mBERT integration\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Load mBERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63829fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained mBERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=3)  # 3 labels for negative, neutral, positive\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a306d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune mBERT model on your preprocessed dataset (not shown here)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1896c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Function to tokenize text for mBERT input\n",
    "def tokenize_text(text):\n",
    "    return tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,  # Adjust as needed\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "# Function to predict sentiment using the fine-tuned mBERT model\n",
    "def predict_sentiment(text):\n",
    "    inputs = tokenize_text(text)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probabilities = torch.softmax(logits, dim=1).tolist()[0]\n",
    "        predicted_class = torch.argmax(logits, dim=1).item()\n",
    "    return predicted_class, probabilities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ce8caed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\anfel\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in c:\\users\\anfel\\anaconda3\\lib\\site-packages (0.17.2)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\anfel\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\anfel\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\anfel\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\anfel\\anaconda3\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\anfel\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\anfel\\anaconda3\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\anfel\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\anfel\\anaconda3\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\anfel\\anaconda3\\lib\\site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\anfel\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\anfel\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdc6115d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...</td>\n",
       "      <td>1</td>\n",
       "      <td>ممتاز نوعا النظافة والموقع والتجهيز والشاطيء ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...</td>\n",
       "      <td>1</td>\n",
       "      <td>أسباب نجاح الإمارات شخص الدولة يعشق ترابها نحب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...</td>\n",
       "      <td>1</td>\n",
       "      <td>هادفة وقوية تنقلك صخب شوارع القاهرة الى هدوء ج...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...</td>\n",
       "      <td>1</td>\n",
       "      <td>خلصنا مبدئيا اللي مستني ابهار زي الفيل الازرق ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل...</td>\n",
       "      <td>1</td>\n",
       "      <td>ياسات جلوريا جزء يتجزأ دبي فندق متكامل الخدمات...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...      1   \n",
       "1  أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...      1   \n",
       "2  هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...      1   \n",
       "3  خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...      1   \n",
       "4  ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل...      1   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  ممتاز نوعا النظافة والموقع والتجهيز والشاطيء ا...  \n",
       "1  أسباب نجاح الإمارات شخص الدولة يعشق ترابها نحب...  \n",
       "2  هادفة وقوية تنقلك صخب شوارع القاهرة الى هدوء ج...  \n",
       "3  خلصنا مبدئيا اللي مستني ابهار زي الفيل الازرق ...  \n",
       "4  ياسات جلوريا جزء يتجزأ دبي فندق متكامل الخدمات...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0c55be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the preprocessed dataset and predict sentiment for each review\n",
    "sentiments = []\n",
    "probabilities = []\n",
    "for text in data['cleaned_text']:\n",
    "    sentiment, probs = predict_sentiment(text)\n",
    "    sentiments.append(sentiment)\n",
    "    probabilities.append(probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc88d4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee28e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f9eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Map sentiment labels back to -1, 0, 1\n",
    "data['predicted_sentiment'] = [sentiment - 1 for sentiment in sentiments]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557f52cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (data['label'] == data['predicted_sentiment']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b40418",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56758b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4ed5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define your dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        \n",
    "        self.texts = texts\n",
    "        \n",
    "        self.labels = labels\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        self.max_length = max_length\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]+1\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b656267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your training and validation datasets\n",
    "train_dataset = CustomDataset(train_data.reset_index(drop=True)['cleaned_text'], train_data.reset_index(drop=True)['label'], tokenizer, max_length=500)\n",
    "valid_dataset = CustomDataset(test_data.reset_index(drop=True)['cleaned_text'], test_data.reset_index(drop=True)['label'], tokenizer, max_length=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2694c577",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=3)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c410105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define optimizer and learning rate scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "num_epochs = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64be794",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define data loaders\n",
    "train_loader = DataLoader(train_dataset)\n",
    "\n",
    "valid_loader = DataLoader(valid_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c65617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fine-tuning loop\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', unit='batch'):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            valid_loss += loss.item()\n",
    "            predictions = torch.argmax(outputs.logits, dim=1)\n",
    "            predicted_labels = predictions - 1\n",
    "            correct_predictions += torch.sum(predicted_labels == labels).item()\n",
    "            total_predictions += len(labels)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss / len(train_loader)}, Validation Loss: {valid_loss / len(valid_loader)}, Validation Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1458d45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...</td>\n",
       "      <td>1</td>\n",
       "      <td>ممتاز نوعا النظافة والموقع والتجهيز والشاطيء ا...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...</td>\n",
       "      <td>1</td>\n",
       "      <td>أسباب نجاح الإمارات شخص الدولة يعشق ترابها نحب...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...</td>\n",
       "      <td>1</td>\n",
       "      <td>هادفة وقوية تنقلك صخب شوارع القاهرة الى هدوء ج...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...</td>\n",
       "      <td>1</td>\n",
       "      <td>خلصنا مبدئيا اللي مستني ابهار زي الفيل الازرق ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل...</td>\n",
       "      <td>1</td>\n",
       "      <td>ياسات جلوريا جزء يتجزأ دبي فندق متكامل الخدمات...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164769</th>\n",
       "      <td>وهلأ لوين؟ ....سؤال اتمنى أن أطرحه في مصر اعتق...</td>\n",
       "      <td>1</td>\n",
       "      <td>وهلأ لوين؟ سؤال اتمنى أطرحه مصر اعتقد كلماتي ا...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164770</th>\n",
       "      <td>قراصنة الكاريبي بحس أنثوي ثلاثي الأبعاد بعد غي...</td>\n",
       "      <td>1</td>\n",
       "      <td>قراصنة الكاريبي بحس أنثوي ثلاثي الأبعاد غياب د...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164771</th>\n",
       "      <td>قصة بسيطة ودراما واقعية إسلوب إخراجي يتسم بالح...</td>\n",
       "      <td>0</td>\n",
       "      <td>قصة بسيطة ودراما واقعية إسلوب إخراجي يتسم بالح...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164772</th>\n",
       "      <td>بزوغ الفجر بتتويج دموي هكذا طل علينا فيلم ملحم...</td>\n",
       "      <td>1</td>\n",
       "      <td>بزوغ الفجر بتتويج دموي طل علينا فيلم ملحمة الش...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164773</th>\n",
       "      <td>غزل البنات وأجمل معاني الحب عفوية وبساطة أجدها...</td>\n",
       "      <td>1</td>\n",
       "      <td>غزل البنات وأجمل معاني الحب عفوية وبساطة أجدها...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164774 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label  \\\n",
       "0       ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...      1   \n",
       "1       أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...      1   \n",
       "2       هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...      1   \n",
       "3       خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...      1   \n",
       "4       ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل...      1   \n",
       "...                                                   ...    ...   \n",
       "164769  وهلأ لوين؟ ....سؤال اتمنى أن أطرحه في مصر اعتق...      1   \n",
       "164770  قراصنة الكاريبي بحس أنثوي ثلاثي الأبعاد بعد غي...      1   \n",
       "164771  قصة بسيطة ودراما واقعية إسلوب إخراجي يتسم بالح...      0   \n",
       "164772  بزوغ الفجر بتتويج دموي هكذا طل علينا فيلم ملحم...      1   \n",
       "164773  غزل البنات وأجمل معاني الحب عفوية وبساطة أجدها...      1   \n",
       "\n",
       "                                             cleaned_text  predicted_sentiment  \n",
       "0       ممتاز نوعا النظافة والموقع والتجهيز والشاطيء ا...                    0  \n",
       "1       أسباب نجاح الإمارات شخص الدولة يعشق ترابها نحب...                    1  \n",
       "2       هادفة وقوية تنقلك صخب شوارع القاهرة الى هدوء ج...                    1  \n",
       "3       خلصنا مبدئيا اللي مستني ابهار زي الفيل الازرق ...                    0  \n",
       "4       ياسات جلوريا جزء يتجزأ دبي فندق متكامل الخدمات...                    0  \n",
       "...                                                   ...                  ...  \n",
       "164769  وهلأ لوين؟ سؤال اتمنى أطرحه مصر اعتقد كلماتي ا...                    1  \n",
       "164770  قراصنة الكاريبي بحس أنثوي ثلاثي الأبعاد غياب د...                    1  \n",
       "164771  قصة بسيطة ودراما واقعية إسلوب إخراجي يتسم بالح...                    0  \n",
       "164772  بزوغ الفجر بتتويج دموي طل علينا فيلم ملحمة الش...                    0  \n",
       "164773  غزل البنات وأجمل معاني الحب عفوية وبساطة أجدها...                    1  \n",
       "\n",
       "[164774 rows x 4 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d193e4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing duplicates and preprocessing, the dataset contains 161660 entries.\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates if needed\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Display the size of the dataset after preprocessing\n",
    "print(\"After removing duplicates and preprocessing, the dataset contains {} entries.\".format(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "902995a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...</td>\n",
       "      <td>1</td>\n",
       "      <td>ممتاز نوعا النظافة والموقع والتجهيز والشاطيء ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...</td>\n",
       "      <td>1</td>\n",
       "      <td>أسباب نجاح الإمارات شخص الدولة يعشق ترابها نحب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...</td>\n",
       "      <td>1</td>\n",
       "      <td>هادفة وقوية تنقلك صخب شوارع القاهرة الى هدوء ج...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...</td>\n",
       "      <td>1</td>\n",
       "      <td>خلصنا مبدئيا اللي مستني ابهار زي الفيل الازرق ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل...</td>\n",
       "      <td>1</td>\n",
       "      <td>ياسات جلوريا جزء يتجزأ دبي فندق متكامل الخدمات...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...      1   \n",
       "1  أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...      1   \n",
       "2  هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...      1   \n",
       "3  خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...      1   \n",
       "4  ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل...      1   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  ممتاز نوعا النظافة والموقع والتجهيز والشاطيء ا...  \n",
       "1  أسباب نجاح الإمارات شخص الدولة يعشق ترابها نحب...  \n",
       "2  هادفة وقوية تنقلك صخب شوارع القاهرة الى هدوء ج...  \n",
       "3  خلصنا مبدئيا اللي مستني ابهار زي الفيل الازرق ...  \n",
       "4  ياسات جلوريا جزء يتجزأ دبي فندق متكامل الخدمات...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stat = data\n",
    "data_stat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "143bcc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Downloading emoji-2.10.1-py2.py3-none-any.whl (421 kB)\n",
      "     -------------------------------------- 421.5/421.5 kB 1.9 MB/s eta 0:00:00\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-2.10.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install emoji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fe45533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label  \\\n",
      "0  ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...      1   \n",
      "1  أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...      1   \n",
      "2  هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...      1   \n",
      "3  خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...      1   \n",
      "4  ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل...      1   \n",
      "\n",
      "                                        cleaned_text  word_count  char_count  \\\n",
      "0  ممتاز نوعا النظافة والموقع والتجهيز والشاطيء ا...           7          51   \n",
      "1  أسباب نجاح الإمارات شخص الدولة يعشق ترابها نحب...          39         222   \n",
      "2  هادفة وقوية تنقلك صخب شوارع القاهرة الى هدوء ج...          34         208   \n",
      "3  خلصنا مبدئيا اللي مستني ابهار زي الفيل الازرق ...          89         492   \n",
      "4  ياسات جلوريا جزء يتجزأ دبي فندق متكامل الخدمات...          11          62   \n",
      "\n",
      "   avg_char_per_word  stopwords_count  emoji_count  \n",
      "0           6.428571                0            0  \n",
      "1           4.717949                0            0  \n",
      "2           5.147059                0            0  \n",
      "3           4.539326                0            0  \n",
      "4           4.727273                0            0  \n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Function to calculate average word length\n",
    "def avg_word(sentence):\n",
    "    words = sentence.split()\n",
    "    if len(words) == 0:\n",
    "        return 0\n",
    "    return (sum(len(word) for word in words) / len(words))\n",
    "\n",
    "# Function to count emojis\n",
    "def emoji_counter(sentence):\n",
    "    return emoji.emoji_count(sentence)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate word count, character count, average characters per word, stopwords count, and emoji count\n",
    "data_stat['word_count'] = data_stat['cleaned_text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "data_stat['char_count'] = data_stat['cleaned_text'].str.len()  # This includes spaces\n",
    "data_stat['avg_char_per_word'] = data_stat['cleaned_text'].apply(lambda x: avg_word(x))\n",
    "stop = stopwords.words('arabic')\n",
    "data_stat['stopwords_count'] = data_stat['cleaned_text'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "data_stat['emoji_count'] = data_stat['cleaned_text'].apply(lambda x: emoji_counter(x))\n",
    "\n",
    "\n",
    "# Display the DataFrame head\n",
    "print(data_stat.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04eda0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_char_per_word</th>\n",
       "      <th>stopwords_count</th>\n",
       "      <th>emoji_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...</td>\n",
       "      <td>1</td>\n",
       "      <td>ممتاز نوعا النظافة والموقع والتجهيز والشاطيء ا...</td>\n",
       "      <td>7</td>\n",
       "      <td>51</td>\n",
       "      <td>6.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...</td>\n",
       "      <td>1</td>\n",
       "      <td>أسباب نجاح الإمارات شخص الدولة يعشق ترابها نحب...</td>\n",
       "      <td>39</td>\n",
       "      <td>222</td>\n",
       "      <td>4.717949</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...</td>\n",
       "      <td>1</td>\n",
       "      <td>هادفة وقوية تنقلك صخب شوارع القاهرة الى هدوء ج...</td>\n",
       "      <td>34</td>\n",
       "      <td>208</td>\n",
       "      <td>5.147059</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...</td>\n",
       "      <td>1</td>\n",
       "      <td>خلصنا مبدئيا اللي مستني ابهار زي الفيل الازرق ...</td>\n",
       "      <td>89</td>\n",
       "      <td>492</td>\n",
       "      <td>4.539326</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل...</td>\n",
       "      <td>1</td>\n",
       "      <td>ياسات جلوريا جزء يتجزأ دبي فندق متكامل الخدمات...</td>\n",
       "      <td>11</td>\n",
       "      <td>62</td>\n",
       "      <td>4.727273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164769</th>\n",
       "      <td>وهلأ لوين؟ ....سؤال اتمنى أن أطرحه في مصر اعتق...</td>\n",
       "      <td>1</td>\n",
       "      <td>وهلأ لوين؟ سؤال اتمنى أطرحه مصر اعتقد كلماتي ا...</td>\n",
       "      <td>306</td>\n",
       "      <td>1859</td>\n",
       "      <td>5.078431</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164770</th>\n",
       "      <td>قراصنة الكاريبي بحس أنثوي ثلاثي الأبعاد بعد غي...</td>\n",
       "      <td>1</td>\n",
       "      <td>قراصنة الكاريبي بحس أنثوي ثلاثي الأبعاد غياب د...</td>\n",
       "      <td>493</td>\n",
       "      <td>3046</td>\n",
       "      <td>5.180527</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164771</th>\n",
       "      <td>قصة بسيطة ودراما واقعية إسلوب إخراجي يتسم بالح...</td>\n",
       "      <td>0</td>\n",
       "      <td>قصة بسيطة ودراما واقعية إسلوب إخراجي يتسم بالح...</td>\n",
       "      <td>218</td>\n",
       "      <td>1371</td>\n",
       "      <td>5.293578</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164772</th>\n",
       "      <td>بزوغ الفجر بتتويج دموي هكذا طل علينا فيلم ملحم...</td>\n",
       "      <td>1</td>\n",
       "      <td>بزوغ الفجر بتتويج دموي طل علينا فيلم ملحمة الش...</td>\n",
       "      <td>447</td>\n",
       "      <td>2876</td>\n",
       "      <td>5.436242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164773</th>\n",
       "      <td>غزل البنات وأجمل معاني الحب عفوية وبساطة أجدها...</td>\n",
       "      <td>1</td>\n",
       "      <td>غزل البنات وأجمل معاني الحب عفوية وبساطة أجدها...</td>\n",
       "      <td>252</td>\n",
       "      <td>1563</td>\n",
       "      <td>5.206349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161660 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label  \\\n",
       "0       ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...      1   \n",
       "1       أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...      1   \n",
       "2       هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...      1   \n",
       "3       خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...      1   \n",
       "4       ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل...      1   \n",
       "...                                                   ...    ...   \n",
       "164769  وهلأ لوين؟ ....سؤال اتمنى أن أطرحه في مصر اعتق...      1   \n",
       "164770  قراصنة الكاريبي بحس أنثوي ثلاثي الأبعاد بعد غي...      1   \n",
       "164771  قصة بسيطة ودراما واقعية إسلوب إخراجي يتسم بالح...      0   \n",
       "164772  بزوغ الفجر بتتويج دموي هكذا طل علينا فيلم ملحم...      1   \n",
       "164773  غزل البنات وأجمل معاني الحب عفوية وبساطة أجدها...      1   \n",
       "\n",
       "                                             cleaned_text  word_count  \\\n",
       "0       ممتاز نوعا النظافة والموقع والتجهيز والشاطيء ا...           7   \n",
       "1       أسباب نجاح الإمارات شخص الدولة يعشق ترابها نحب...          39   \n",
       "2       هادفة وقوية تنقلك صخب شوارع القاهرة الى هدوء ج...          34   \n",
       "3       خلصنا مبدئيا اللي مستني ابهار زي الفيل الازرق ...          89   \n",
       "4       ياسات جلوريا جزء يتجزأ دبي فندق متكامل الخدمات...          11   \n",
       "...                                                   ...         ...   \n",
       "164769  وهلأ لوين؟ سؤال اتمنى أطرحه مصر اعتقد كلماتي ا...         306   \n",
       "164770  قراصنة الكاريبي بحس أنثوي ثلاثي الأبعاد غياب د...         493   \n",
       "164771  قصة بسيطة ودراما واقعية إسلوب إخراجي يتسم بالح...         218   \n",
       "164772  بزوغ الفجر بتتويج دموي طل علينا فيلم ملحمة الش...         447   \n",
       "164773  غزل البنات وأجمل معاني الحب عفوية وبساطة أجدها...         252   \n",
       "\n",
       "        char_count  avg_char_per_word  stopwords_count  emoji_count  \n",
       "0               51           6.428571                0            0  \n",
       "1              222           4.717949                0            0  \n",
       "2              208           5.147059                0            0  \n",
       "3              492           4.539326                0            0  \n",
       "4               62           4.727273                0            0  \n",
       "...            ...                ...              ...          ...  \n",
       "164769        1859           5.078431                0            0  \n",
       "164770        3046           5.180527                0            0  \n",
       "164771        1371           5.293578                0            0  \n",
       "164772        2876           5.436242                0            0  \n",
       "164773        1563           5.206349                0            0  \n",
       "\n",
       "[161660 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f574598a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
      "     -------------------------------------- 626.3/626.3 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting nltk>=3.8\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\anfel\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (2022.7.9)\n",
      "Requirement already satisfied: click in c:\\users\\anfel\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\anfel\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anfel\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\anfel\\anaconda3\\lib\\site-packages (from click->nltk>=3.8->textblob) (0.4.5)\n",
      "Installing collected packages: nltk, textblob\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.7\n",
      "    Uninstalling nltk-3.7:\n",
      "      Successfully uninstalled nltk-3.7\n",
      "Successfully installed nltk-3.8.1 textblob-0.18.0.post0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "196c9292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tashaphyne\n",
      "  Downloading Tashaphyne-0.3.6-py3-none-any.whl (251 kB)\n",
      "     -------------------------------------- 251.5/251.5 kB 1.9 MB/s eta 0:00:00\n",
      "Collecting pyarabic\n",
      "  Downloading PyArabic-0.6.15-py3-none-any.whl (126 kB)\n",
      "     -------------------------------------- 126.4/126.4 kB 3.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\anfel\\anaconda3\\lib\\site-packages (from pyarabic->tashaphyne) (1.16.0)\n",
      "Installing collected packages: pyarabic, tashaphyne\n",
      "Successfully installed pyarabic-0.6.15 tashaphyne-0.3.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tashaphyne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ddc492b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement dsaraby (from versions: none)\n",
      "ERROR: No matching distribution found for dsaraby\n"
     ]
    }
   ],
   "source": [
    "pip install dsaraby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ea5ee6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from tashaphyne.stemming import ArabicLightStemmer\n",
    "import pyarabic.araby as araby\n",
    "\n",
    "\n",
    "\n",
    "# Define Arabic stopwords\n",
    "stops = set(stopwords.words(\"arabic\"))\n",
    "stop_word_comp = {\"،\", \"آض\", \"آمينَ\", \"آه\", \"آهاً\", \"آي\", \"أ\", \"أب\", \"أجل\", \"أجمع\", \"أخ\", \"أخذ\", \"أصبح\", \"أضحى\", \"أقبل\", \"أقل\", \"أكثر\", \"ألا\", \"أم\", \"أما\", \"أمامك\", \"أمامكَ\", \"أمسى\", \"أمّا\", \"أن\", \"أنا\", \"أنت\", \"أنتم\", \"أنتما\", \"أنتن\", \"أنتِ\", \"أنشأ\", \"أنّى\", \"أو\", \"أوشك\", \"أولئك\", \"أولئكم\", \"أولاء\", \"أولالك\", \"أوّهْ\", \"أي\", \"أيا\", \"أين\", \"أينما\", \"أيّ\", \"أَنَّ\", \"أََيُّ\", \"أُفٍّ\", \"إذ\", \"إذا\", \"إذاً\", \"إذما\", \"إذن\", \"إلى\", \"إليكم\", \"إليكما\", \"إليكنّ\", \"إليكَ\", \"إلَيْكَ\", \"إلّا\", \"إمّا\", \"إن\", \"إنّما\", \"إي\", \"إياك\", \"إياكم\", \"إياكما\", \"إياكن\", \"إيانا\", \"إياه\", \"إياها\", \"إياهم\", \"إياهما\", \"إياهن\", \"إياي\", \"إيهٍ\", \"إِنَّ\", \"ا\", \"ابتدأ\", \"اثر\", \"احد\", \"اخرى\", \"اخلولق\", \"اذا\", \"اربعة\", \"ارتدّ\", \"استحال\", \"اطار\", \"اعادة\", \"اعلنت\", \"اف\", \"اكثر\", \"اكد\", \"الألاء\", \"الألى\", \"الا\", \"الاخيرة\", \"الان\", \"الاول\", \"الاولى\", \"التى\", \"التي\", \"الثاني\", \"الثانية\", \"الذاتي\", \"الذى\", \"الذي\", \"الذين\", \"السابق\", \"الف\", \"اللائي\", \"اللاتي\", \"اللتان\", \"اللتيا\", \"اللتين\", \"اللذان\", \"اللذين\", \"اللواتي\", \"الماضي\", \"المقبل\", \"الوقت\", \"الى\", \"اليوم\", \"اما\", \"امام\", \"امس\", \"ان\", \"انبرى\", \"انقلب\", \"انه\", \"انها\", \"او\", \"اول\", \"اي\", \"ايار\", \"ايام\", \"ايضا\", \"ب\", \"بات\", \"باسم\", \"بان\", \"بخٍ\", \"برس\", \"بسبب\", \"بسّ\", \"بشكل\", \"بضع\", \"بطآن\", \"بعد\", \"بعض\", \"بك\", \"بكم\", \"بكما\", \"بكن\", \"بل\", \"بلى\", \"بما\", \"بماذا\", \"بمن\", \"بن\", \"بنا\", \"به\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a9fd162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install arabic-transliterate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b190396b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Anfel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "897ec5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label  \\\n",
      "0  ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...      1   \n",
      "1  أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...      1   \n",
      "2  هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...      1   \n",
      "3  خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...      1   \n",
      "4  ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل...      1   \n",
      "\n",
      "                                        cleaned_text  word_count  char_count  \\\n",
      "0  mmtaz nwaa ma alndaf walmwqa waltjhyz walshaty...           7          51   \n",
      "1  hd sbab njah alاmarat اn kl shkhs fy hdhh aldw...          39         222   \n",
      "2  hadf wqwy tnqlk mn skhb shwara alqahr alي hdwء...          34         208   \n",
      "3  khlsna mbdءya ally mstny abhar zy alfyl alazrq...          89         492   \n",
      "4  yasat jlwrya jzء la ytjzا mn dby fndq mtkaml a...          11          62   \n",
      "\n",
      "   avg_char_per_word  stopwords_count  emoji_count  \n",
      "0           6.428571                0            0  \n",
      "1           4.717949                0            0  \n",
      "2           5.147059                0            0  \n",
      "3           4.539326                0            0  \n",
      "4           4.727273                0            0  \n"
     ]
    }
   ],
   "source": [
    "# Initialize Arabic stemmer\n",
    "ArListem = ArabicLightStemmer()\n",
    "\n",
    "# Function to stem Arabic words\n",
    "def stem(text):\n",
    "    zen = TextBlob(text)\n",
    "    words = zen.words\n",
    "    cleaned = []\n",
    "    for w in words:\n",
    "        cleaned.append(ArListem.light_stem(w))\n",
    "    return \" \".join(cleaned)\n",
    "\n",
    "# Function to normalize Arabic text\n",
    "def normalizeArabic(text):\n",
    "    text = text.strip()\n",
    "    text = re.sub(\"[إأٱآا]\", \"ا\", text)\n",
    "    text = re.sub(\"ى\", \"ي\", text)\n",
    "    text = re.sub(\"ؤ\", \"ء\", text)\n",
    "    text = re.sub(\"ئ\", \"ء\", text)\n",
    "    text = re.sub(\"ة\", \"ه\", text)\n",
    "    noise = re.compile(\"\"\" ّ    | # Tashdid\n",
    "                             َ    | # Fatha\n",
    "                             ً    | # Tanwin Fath\n",
    "                             ُ    | # Damma\n",
    "                             ٌ    | # Tanwin Damm\n",
    "                             ِ    | # Kasra\n",
    "                             ٍ    | # Tanwin Kasr\n",
    "                             ْ    | # Sukun\n",
    "                             ـ     # Tatwil/Kashida\n",
    "                         \"\"\", re.VERBOSE)\n",
    "    text = re.sub(noise, '', text)\n",
    "    text = re.sub(r'(.)\\1+', r\"\\1\\1\", text) # Remove longation\n",
    "    return araby.strip_tashkeel(text)\n",
    "\n",
    "# Function to remove stopwords\n",
    "def remove_stop_words(text):\n",
    "    zen = TextBlob(text)\n",
    "    words = zen.words\n",
    "    return \" \".join([w for w in words if not w in stopwords_list and len(w) >= 2])\n",
    "\n",
    "# Apply text preprocessing functions to the 'text' column\n",
    "data_stat['cleaned_text'] = data_stat['cleaned_text'].apply(stem)\n",
    "data_stat['cleaned_text'] = data_stat['cleaned_text'].apply(normalizeArabic)\n",
    "data_stat['cleaned_text'] = data_stat['cleaned_text'].apply(remove_stop_words)\n",
    "\n",
    "# Display the DataFrame head\n",
    "print(data_stat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38b4f035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_char_per_word</th>\n",
       "      <th>stopwords_count</th>\n",
       "      <th>emoji_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...</td>\n",
       "      <td>1</td>\n",
       "      <td>mmtaz nwaa ma alndaf walmwqa waltjhyz walshaty...</td>\n",
       "      <td>7</td>\n",
       "      <td>51</td>\n",
       "      <td>6.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...</td>\n",
       "      <td>1</td>\n",
       "      <td>hd sbab njah alاmarat اn kl shkhs fy hdhh aldw...</td>\n",
       "      <td>39</td>\n",
       "      <td>222</td>\n",
       "      <td>4.717949</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...</td>\n",
       "      <td>1</td>\n",
       "      <td>hadf wqwy tnqlk mn skhb shwara alqahr alي hdwء...</td>\n",
       "      <td>34</td>\n",
       "      <td>208</td>\n",
       "      <td>5.147059</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...</td>\n",
       "      <td>1</td>\n",
       "      <td>khlsna mbdءya ally mstny abhar zy alfyl alazrq...</td>\n",
       "      <td>89</td>\n",
       "      <td>492</td>\n",
       "      <td>4.539326</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل...</td>\n",
       "      <td>1</td>\n",
       "      <td>yasat jlwrya jzء la ytjzا mn dby fndq mtkaml a...</td>\n",
       "      <td>11</td>\n",
       "      <td>62</td>\n",
       "      <td>4.727273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164769</th>\n",
       "      <td>وهلأ لوين؟ ....سؤال اتمنى أن أطرحه في مصر اعتق...</td>\n",
       "      <td>1</td>\n",
       "      <td>whlا lwyn؟ sءal atmnي اn trhh fy msr aatqd اn ...</td>\n",
       "      <td>306</td>\n",
       "      <td>1859</td>\n",
       "      <td>5.078431</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164770</th>\n",
       "      <td>قراصنة الكاريبي بحس أنثوي ثلاثي الأبعاد بعد غي...</td>\n",
       "      <td>1</td>\n",
       "      <td>qrasn alkaryby bhs nthwy thlathy alاbaad bad g...</td>\n",
       "      <td>493</td>\n",
       "      <td>3046</td>\n",
       "      <td>5.180527</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164771</th>\n",
       "      <td>قصة بسيطة ودراما واقعية إسلوب إخراجي يتسم بالح...</td>\n",
       "      <td>0</td>\n",
       "      <td>qs bsyt wdrama waqay اslwb اkhrajy ytsm balhsy...</td>\n",
       "      <td>218</td>\n",
       "      <td>1371</td>\n",
       "      <td>5.293578</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164772</th>\n",
       "      <td>بزوغ الفجر بتتويج دموي هكذا طل علينا فيلم ملحم...</td>\n",
       "      <td>1</td>\n",
       "      <td>bzwgh alfjr bttwyj dmwy hkdha tl alyna fylm ml...</td>\n",
       "      <td>447</td>\n",
       "      <td>2876</td>\n",
       "      <td>5.436242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164773</th>\n",
       "      <td>غزل البنات وأجمل معاني الحب عفوية وبساطة أجدها...</td>\n",
       "      <td>1</td>\n",
       "      <td>ghzl albnat wاjml maany alhb afwy wbsat jdha d...</td>\n",
       "      <td>252</td>\n",
       "      <td>1563</td>\n",
       "      <td>5.206349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161660 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label  \\\n",
       "0       ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...      1   \n",
       "1       أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...      1   \n",
       "2       هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...      1   \n",
       "3       خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...      1   \n",
       "4       ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل...      1   \n",
       "...                                                   ...    ...   \n",
       "164769  وهلأ لوين؟ ....سؤال اتمنى أن أطرحه في مصر اعتق...      1   \n",
       "164770  قراصنة الكاريبي بحس أنثوي ثلاثي الأبعاد بعد غي...      1   \n",
       "164771  قصة بسيطة ودراما واقعية إسلوب إخراجي يتسم بالح...      0   \n",
       "164772  بزوغ الفجر بتتويج دموي هكذا طل علينا فيلم ملحم...      1   \n",
       "164773  غزل البنات وأجمل معاني الحب عفوية وبساطة أجدها...      1   \n",
       "\n",
       "                                             cleaned_text  word_count  \\\n",
       "0       mmtaz nwaa ma alndaf walmwqa waltjhyz walshaty...           7   \n",
       "1       hd sbab njah alاmarat اn kl shkhs fy hdhh aldw...          39   \n",
       "2       hadf wqwy tnqlk mn skhb shwara alqahr alي hdwء...          34   \n",
       "3       khlsna mbdءya ally mstny abhar zy alfyl alazrq...          89   \n",
       "4       yasat jlwrya jzء la ytjzا mn dby fndq mtkaml a...          11   \n",
       "...                                                   ...         ...   \n",
       "164769  whlا lwyn؟ sءal atmnي اn trhh fy msr aatqd اn ...         306   \n",
       "164770  qrasn alkaryby bhs nthwy thlathy alاbaad bad g...         493   \n",
       "164771  qs bsyt wdrama waqay اslwb اkhrajy ytsm balhsy...         218   \n",
       "164772  bzwgh alfjr bttwyj dmwy hkdha tl alyna fylm ml...         447   \n",
       "164773  ghzl albnat wاjml maany alhb afwy wbsat jdha d...         252   \n",
       "\n",
       "        char_count  avg_char_per_word  stopwords_count  emoji_count  \n",
       "0               51           6.428571                0            0  \n",
       "1              222           4.717949                0            0  \n",
       "2              208           5.147059                0            0  \n",
       "3              492           4.539326                0            0  \n",
       "4               62           4.727273                0            0  \n",
       "...            ...                ...              ...          ...  \n",
       "164769        1859           5.078431                0            0  \n",
       "164770        3046           5.180527                0            0  \n",
       "164771        1371           5.293578                0            0  \n",
       "164772        2876           5.436242                0            0  \n",
       "164773        1563           5.206349                0            0  \n",
       "\n",
       "[161660 rows x 8 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5dd727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed data to a new file\n",
    "data.to_csv(\"preprocessed_data.tsv\", sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54123b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
